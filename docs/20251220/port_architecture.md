# CrucibleDatasets Port Architecture

**Date**: 2025-12-20
**Status**: v0.3.0 - Thin Fetch Layer Complete

## Architecture Comparison

### Python `datasets` Library (Full Stack)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        load_dataset("gsm8k")                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  load.py (1,576 lines)                                                  â”‚
â”‚  â”œâ”€ Resolve dataset name â†’ HuggingFace Hub or local                     â”‚
â”‚  â”œâ”€ Find builder class (Parquet, JSON, CSV, etc.)                       â”‚
â”‚  â”œâ”€ Load/create BuilderConfig                                           â”‚
â”‚  â””â”€ Orchestrate download â†’ build â†’ cache pipeline                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  builder.py (1,896 lines)                                               â”‚
â”‚  â”œâ”€ DatasetBuilder base class                                           â”‚
â”‚  â”œâ”€ GeneratorBasedBuilder (yields examples)                             â”‚
â”‚  â”œâ”€ ArrowBasedBuilder (yields Arrow tables)                             â”‚
â”‚  â”œâ”€ Split generation and management                                     â”‚
â”‚  â””â”€ Fingerprinting for cache invalidation                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  download/ (650 lines)                                                  â”‚
â”‚  â”œâ”€ DownloadManager - coordinate downloads                              â”‚
â”‚  â”œâ”€ StreamingDownloadManager - lazy downloads                           â”‚
â”‚  â””â”€ Caching, checksums, extraction                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  packaged_modules/parquet/parquet.py (190 lines)                        â”‚
â”‚  â”œâ”€ ParquetConfig (columns, filters, batch_size)                        â”‚
â”‚  â”œâ”€ Schema inference from Parquet metadata                              â”‚
â”‚  â”œâ”€ Row group iteration with predicate pushdown                         â”‚
â”‚  â””â”€ Batch yielding with PyArrow                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  table.py (2,385 lines)                                                 â”‚
â”‚  â”œâ”€ InMemoryTable, MemoryMappedTable, ConcatenationTable                â”‚
â”‚  â”œâ”€ PyArrow table wrappers with 283+ pa.* calls                         â”‚
â”‚  â”œâ”€ Slice, filter, map, cast operations                                 â”‚
â”‚  â””â”€ Memory-mapped disk access                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  arrow_dataset.py (6,836 lines) - THE BEAST                             â”‚
â”‚  â”œâ”€ Dataset class - main user-facing API                                â”‚
â”‚  â”œâ”€ map(), filter(), select(), shuffle(), etc.                          â”‚
â”‚  â”œâ”€ Batched processing with Arrow                                       â”‚
â”‚  â”œâ”€ Format conversion (torch, tf, numpy, pandas)                        â”‚
â”‚  â””â”€ Caching and fingerprinting                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  features/features.py (2,330 lines)                                     â”‚
â”‚  â”œâ”€ Value, ClassLabel, Sequence, Audio, Image, etc.                     â”‚
â”‚  â”œâ”€ Arrow schema â†” Features conversion                                  â”‚
â”‚  â”œâ”€ Type casting and coercion                                           â”‚
â”‚  â””â”€ Nested structure handling                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total: ~26,000+ lines Python + PyArrow C++ (500K+ lines)
```

### Elixir CrucibleDatasets (Thin Fetch Layer)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CrucibleDatasets.Loader.GSM8K.load()                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Loader.GSM8K (283 lines)                                               â”‚
â”‚  â”œâ”€ load(opts) - entry point                                            â”‚
â”‚  â”œâ”€ Synthetic fallback for offline testing                              â”‚
â”‚  â”œâ”€ HuggingFace.fetch() for real data                                   â”‚
â”‚  â””â”€ parse_huggingface_data() - transform to our format                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Fetcher.HuggingFace (463 lines)                                        â”‚
â”‚  â”œâ”€ list_files() - API call to get repo contents                        â”‚
â”‚  â”œâ”€ download_file() - HTTP GET with redirects                           â”‚
â”‚  â”œâ”€ fetch() - orchestrate file discovery + download                     â”‚
â”‚  â”œâ”€ find_split_files() - match train/test patterns                      â”‚
â”‚  â””â”€ parse_file() - Parquet/JSONL/JSON/CSV                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Explorer.DataFrame (Rust/Polars - external)                            â”‚
â”‚  â”œâ”€ from_parquet!() - parse Parquet file                                â”‚
â”‚  â”œâ”€ to_rows() - convert to list of maps                                 â”‚
â”‚  â””â”€ (We don't use streaming, column projection, etc.)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dataset struct (simple)                                                â”‚
â”‚  â”œâ”€ name, version, items (list), metadata                               â”‚
â”‚  â””â”€ No Arrow tables, no memory mapping                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total: ~1,500 lines Elixir + Explorer (Rust)
```

## What Each Layer Does

### Python Layer Breakdown

| File | Lines | Key Responsibilities |
|------|-------|---------------------|
| `load.py` | 1,576 | Dataset resolution, config loading, pipeline orchestration |
| `builder.py` | 1,896 | Abstract builders, split generation, fingerprinting |
| `arrow_dataset.py` | 6,836 | Dataset class, all transformations, format conversion |
| `iterable_dataset.py` | 4,714 | Streaming/lazy loading, on-the-fly processing |
| `dataset_dict.py` | 2,852 | Multi-split handling, parallel operations |
| `table.py` | 2,385 | Arrow table wrappers, memory mapping |
| `features/features.py` | 2,330 | Type system, schema conversion |
| `data_files.py` | 814 | File pattern matching, discovery |
| `arrow_reader.py` | 620 | Arrow/Parquet file reading |
| `arrow_writer.py` | 722 | Arrow file writing, caching |
| `download/` | 650 | Download management, caching |
| `packaged_modules/` | 3,407 | Format-specific loaders |

### Elixir Layer Breakdown

| File | Lines | Key Responsibilities |
|------|-------|---------------------|
| `huggingface.ex` | 463 | HTTP fetching, URL patterns, file parsing |
| `gsm8k.ex` | 283 | GSM8K-specific loading, answer extraction |
| `math.ex` | ~200 | MATH-500, DeepMath, POLARIS loaders |
| `chat.ex` | ~200 | Tulu, No Robots loaders |
| `preference.ex` | ~250 | HH-RLHF, HelpSteer, UltraFeedback loaders |
| `code.ex` | ~150 | DeepCoder loader |
| `types/*.ex` | ~300 | Message, Conversation, Comparison types |
| `sampler.ex` | ~150 | shuffle, take, skip, filter, k_fold |
| `dataset.ex` | ~100 | Dataset struct and helpers |

## Feature Comparison Matrix

| Feature | Python `datasets` | Our Elixir Port | Gap |
|---------|------------------|-----------------|-----|
| **Data Loading** |
| Parquet parsing | PyArrow (C++ memory-mapped) | Explorer (Rust Polars) | Comparable |
| JSONL parsing | Built-in | Jason + String.split | Comparable |
| CSV parsing | pandas-style | Basic split | Minor |
| Arrow IPC | Full support | Not supported | Major |
| **Data Access** |
| Row iteration | Lazy, memory-mapped | Eager, in-memory | Major |
| Column projection | Predicate pushdown | Read all columns | Major |
| Row filtering | Pushed to file level | Post-load filter | Major |
| Batching | Configurable batch_size | All at once | Major |
| **Memory Management** |
| Memory mapping | Yes, zero-copy | No | Major |
| Streaming | True lazy iteration | Download all first | Major |
| Out-of-core | Handles TB datasets | Memory-limited | Major |
| **Caching** |
| Disk cache | Arrow format, fingerprinted | None | Major |
| Download cache | With checksums | None (re-downloads) | Major |
| Transform cache | Fingerprinted | None | Major |
| **Type System** |
| Schema inference | From Arrow/Parquet metadata | Read first row | Moderate |
| Type coercion | Complex Features system | Basic Elixir maps | Major |
| Nested types | Audio, Image, Sequence, etc. | Not supported | Major |
| **Transformations** |
| map() | Batched, cached, parallel | Enum.map (eager) | Moderate |
| filter() | Predicate pushdown | Enum.filter (eager) | Moderate |
| shuffle() | Efficient with indices | Full copy | Minor |
| select_columns() | Zero-copy projection | Not implemented | Moderate |
| **Splits** |
| Train/test/val | Full split management | Basic support | Minor |
| K-fold | Not built-in | Implemented | N/A (we have it) |
| Stratified | Not built-in | Implemented | N/A (we have it) |
| **Integration** |
| PyTorch DataLoader | Native | N/A | N/A |
| TensorFlow | Native | N/A | N/A |
| Nx tensors | N/A | Could add | Future |

## What We Actually Need vs. What We Have

### For Research/Evaluation Use Cases

| Need | Status | Notes |
|------|--------|-------|
| Load standard benchmarks | âœ… Done | GSM8K, MATH, Chat, Preference, Code |
| Sample datasets | âœ… Done | shuffle, take, skip, filter |
| Train/test splits | âœ… Done | train_test_split, k_fold |
| Evaluate predictions | âœ… Done | exact_match, F1, BLEU, ROUGE |
| Offline testing | âœ… Done | synthetic: true fallback |
| Basic type safety | ğŸ”„ Designed | Sinter schemas (not yet implemented) |

### For Production/Large-Scale

| Need | Status | Notes |
|------|--------|-------|
| Stream 1M+ rows | âŒ Missing | Would need lazy iteration |
| Cache downloads | âŒ Missing | Re-downloads every time |
| Memory efficiency | âŒ Missing | Loads all into memory |
| Column projection | âŒ Missing | Reads all columns |
| Predicate pushdown | âŒ Missing | Filters after load |

## Code Size Comparison

```
Python datasets library:
â”œâ”€â”€ Core files:         ~26,000 lines
â”œâ”€â”€ Features/types:      ~4,200 lines
â”œâ”€â”€ Packaged modules:    ~3,400 lines
â”œâ”€â”€ Utils:               ~3,000 lines
â”œâ”€â”€ Tests:              ~15,000 lines
â””â”€â”€ Total:              ~50,000+ lines Python

Plus PyArrow C++ dependency: ~500,000+ lines

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Elixir CrucibleDatasets:
â”œâ”€â”€ Core files:          ~1,500 lines
â”œâ”€â”€ Loaders:              ~800 lines
â”œâ”€â”€ Types:                ~300 lines
â”œâ”€â”€ Examples:             ~500 lines
â”œâ”€â”€ Tests:               ~1,000 lines
â””â”€â”€ Total:               ~4,100 lines Elixir

Plus Explorer (Rust/Polars): external dep
```

## Architectural Decisions

### Why Thin Fetch Layer?

1. **Elixir Strengths are Different**
   - Python: Data science, ML pipelines, notebooks
   - Elixir: Concurrent systems, fault tolerance, distributed
   - We don't need Python's data science machinery

2. **Explorer Handles Heavy Lifting**
   - Polars/Rust for Parquet parsing
   - Already optimized, battle-tested
   - No need to reimplement Arrow

3. **Research Focus**
   - Evaluation workflows, not training
   - Reasonable dataset sizes (<1M rows)
   - Emphasis on correctness over throughput

4. **Pragmatic Porting**
   - 1,500 lines vs 50,000 lines
   - 95% of use cases with 5% of code
   - Can extend when needed

### What We Deliberately Skipped

| Python Feature | Why Skipped | Alternative |
|----------------|-------------|-------------|
| Arrow memory mapping | Elixir isn't memory-optimized like Python/C++ | Load smaller samples |
| Streaming iteration | BEAM has different memory model | Use sample_size option |
| Transform caching | Less critical for eval workflows | Re-run transforms |
| Format conversion | Don't need PyTorch/TF tensors | Use Nx directly |
| Dataset builders | Over-engineered for our needs | Simple load functions |
| Fingerprinting | Overkill for research use | Trust user |

## Future Enhancement Paths

### If We Need Streaming (Phase 2)

```elixir
defmodule CrucibleDatasets.Stream do
  @doc "Lazy iteration over large datasets"
  def stream(repo_id, opts \\ []) do
    Stream.resource(
      fn -> init_parquet_reader(repo_id, opts) end,
      fn reader -> read_next_batch(reader) end,
      fn reader -> close_reader(reader) end
    )
  end
end
```

Would require:
- Row group-level reading in Explorer
- Streaming HTTP downloads
- ~500 additional lines

### If We Need Caching (Phase 2)

```elixir
defmodule CrucibleDatasets.Cache do
  @cache_dir "~/.crucible_datasets/cache"

  def cached_fetch(repo_id, opts) do
    cache_key = hash({repo_id, opts})
    cache_path = Path.join(@cache_dir, cache_key)

    if File.exists?(cache_path) do
      load_cached(cache_path)
    else
      data = HuggingFace.fetch(repo_id, opts)
      save_cached(cache_path, data)
      data
    end
  end
end
```

Would require:
- Cache directory management
- Serialization format (ETF or Parquet)
- Cache invalidation strategy
- ~300 additional lines

### If We Need Full Type System (Phase 2)

Already designed in `type_system_design.md`:
- Sinter-based schemas
- HuggingFace format adapters
- Registry pattern
- ~800 additional lines

## Summary

| Aspect | Python | Elixir | Ratio |
|--------|--------|--------|-------|
| Lines of code | 50,000+ | 4,100 | 12x smaller |
| Native deps | PyArrow (500K C++) | Explorer (Rust) | Similar |
| Memory model | Zero-copy, mapped | Eager, in-memory | Different |
| Primary use | Training pipelines | Eval research | Different |
| Complexity | Full ML framework | Thin fetch layer | Intentional |

**Bottom Line**: We built exactly what we need - a thin, working fetch layer that covers 95% of research/evaluation use cases with 5% of the code. The gaps are known and can be filled incrementally if needed.
